{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "from argparse import ArgumentParser\n",
    "import numpy as np\n",
    "import torch\n",
    "from data import PermutedMNIST\n",
    "from train import train\n",
    "from model import MLP\n",
    "import utils\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "fisher_estimation_sample_size = 2048\n",
    "weight_decay = 0\n",
    "cuda=True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.fastest = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img,labels):\n",
    "    fig = plt.figure()\n",
    "    for i in range(6):\n",
    "        plt.subplot(2,3,i+1)\n",
    "        plt.tight_layout()\n",
    "        plt.imshow(img[i].view(28,28), cmap='gray', interpolation='none')\n",
    "        plt.title(\"Ground Truth: {}\".format(labels[i]))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "            \n",
    "            \n",
    "def get_permute_mnist():\n",
    "   \n",
    "    train_loader = {}\n",
    "    test_loader = {}\n",
    "    idx = list(range(28 * 28))\n",
    "    for i in range(task_number):\n",
    "        train_loader[i] = torch.utils.data.DataLoader(PermutedMNIST(train = True, permute_idx=idx),\n",
    "                                                      batch_size=batch_size,\n",
    "                                                      num_workers=4)\n",
    "        test_loader[i] = torch.utils.data.DataLoader(PermutedMNIST(train = False, permute_idx= idx),\n",
    "                                                     batch_size=batch_size)\n",
    "        random.shuffle(idx)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "train_loader, test_loader = get_permute_mnist()\n",
    "\n",
    "#unpermuted data:\n",
    "examples_unpermuted = enumerate(train_loader[0])\n",
    "\n",
    "_, (example_data_unpermuted, example_targets_unpermuted) = next(examples_unpermuted)\n",
    "\n",
    "imshow(example_data_unpermuted[:6], example_targets_unpermuted[:6])\n",
    "\n",
    "#permuted data:\n",
    "examples_permuted = enumerate(train_loader[1])\n",
    "\n",
    "_, (example_data_permuted, example_targets_permuted) = next(examples_permuted)\n",
    "imshow(example_data_permuted[:6], example_targets_permuted[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#could also cut last 5 items which are ignored by early stopping\n",
    "def loss_plot(x):\n",
    "    num_epochs = 0\n",
    "    for task in range(1, task_number+1):\n",
    "        plt.plot(range(num_epochs+1, num_epochs + 1 + len(x[task])), x[task] )\n",
    "        num_epochs+= len(x[task])\n",
    "        \n",
    "def accuracy_plot(x):\n",
    "    total_epochs = len(x[1])\n",
    "    for task in range(1, task_number + 1):\n",
    "        plt.plot(range(total_epochs+1 - len(x[task]), total_epochs+1), x[task] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_precision_plot(precisions, labels = []): #precisions needs to be in the form of the return value of train\n",
    "    for num, precision in enumerate(precisions):    \n",
    "        avg_precisions = []\n",
    "        total_epochs = task_number*epochs_per_task\n",
    "        for epoch in range (total_epochs):\n",
    "            avg_precision = 0\n",
    "            tasks_considered = epoch // epochs_per_task +1 #gives 1 for first task, 2 for second,...\n",
    "            for i in range(1,tasks_considered+1): #\n",
    "                avg_precision += precision[i][epoch - (i-1)*epochs_per_task]\n",
    "            avg_precision/=tasks_considered\n",
    "            avg_precisions.append(avg_precision)\n",
    "        plt.ylim(0.88, 0.94)\n",
    "        if (len(labels) == len(precisions)):\n",
    "            plt.plot(range(total_epochs), avg_precisions, label = labels[num])\n",
    "        else:\n",
    "            plt.plot(range(total_epochs), avg_precisions)\n",
    "    plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#high learning rate, no dropout, no early stopping\n",
    "hidden_size1=512\n",
    "hidden_size2 = 256\n",
    "lamda=400\n",
    "lr=2.e-2\n",
    "hidden_dropout_prob=0\n",
    "input_dropout_prob=0\n",
    "early_stopping = False\n",
    "consolidate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the model.\n",
    "mlp_no_dropout_no_earlystopping = MLP( 28*28, 10,\n",
    "    hidden_size1,\n",
    "    hidden_size2,\n",
    "    hidden_dropout_prob,\n",
    "    input_dropout_prob,\n",
    "    lamda,\n",
    ")\n",
    "\n",
    "# initialize the weights.\n",
    "utils.gaussian_initialize(mlp_no_dropout_no_earlystopping)\n",
    "\n",
    "# prepare the cuda if needed.\n",
    "if cuda:\n",
    "    mlp_no_dropout_no_earlystopping.cuda()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> task: 1/10 | epoch: 1/60 | progress: [60032/60000] (100%) | prec: 0.8021 | loss => ce: 0.8103 / ewc: 0.0 / total: 0.8103: : 469it [00:01, 302.37it/s]\n",
      "=> task: 1/10 | epoch: 2/60 | progress: [60032/60000] (100%) | prec: 0.8958 | loss => ce: 0.4838 / ewc: 0.0 / total: 0.4838: : 469it [00:01, 370.62it/s]\n",
      "=> task: 1/10 | epoch: 3/60 | progress: [60032/60000] (100%) | prec: 0.9375 | loss => ce: 0.4192 / ewc: 0.0 / total: 0.4192: : 469it [00:01, 378.79it/s]  \n",
      "=> task: 1/10 | epoch: 4/60 | progress: [60032/60000] (100%) | prec: 0.9375 | loss => ce: 0.3865 / ewc: 0.0 / total: 0.3865: : 469it [00:01, 381.37it/s]  \n",
      "=> task: 1/10 | epoch: 5/60 | progress: [60032/60000] (100%) | prec: 0.9375 | loss => ce: 0.3637 / ewc: 0.0 / total: 0.3637: : 469it [00:01, 394.07it/s]  \n",
      "=> task: 1/10 | epoch: 6/60 | progress: [60032/60000] (100%) | prec: 0.9479 | loss => ce: 0.3436 / ewc: 0.0 / total: 0.3436: : 469it [00:01, 372.93it/s]  \n",
      "=> task: 1/10 | epoch: 7/60 | progress: [60032/60000] (100%) | prec: 0.9479 | loss => ce: 0.3252 / ewc: 0.0 / total: 0.3252: : 469it [00:01, 380.33it/s]  \n",
      "=> task: 1/10 | epoch: 8/60 | progress: [60032/60000] (100%) | prec: 0.9479 | loss => ce: 0.3102 / ewc: 0.0 / total: 0.3102: : 469it [00:01, 370.57it/s]  \n",
      "=> task: 1/10 | epoch: 9/60 | progress: [60032/60000] (100%) | prec: 0.9583 | loss => ce: 0.2977 / ewc: 0.0 / total: 0.2977: : 469it [00:01, 378.92it/s]  \n",
      "=> task: 1/10 | epoch: 10/60 | progress: [60032/60000] (100%) | prec: 0.9688 | loss => ce: 0.2867 / ewc: 0.0 / total: 0.2867: : 469it [00:01, 370.99it/s]  \n",
      "=> task: 1/10 | epoch: 11/60 | progress: [60032/60000] (100%) | prec: 0.9688 | loss => ce: 0.2775 / ewc: 0.0 / total: 0.2775: : 469it [00:01, 368.17it/s]  \n",
      "=> task: 1/10 | epoch: 12/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.2697 / ewc: 0.0 / total: 0.2697: : 469it [00:01, 370.12it/s] \n",
      "=> task: 1/10 | epoch: 13/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.2633 / ewc: 0.0 / total: 0.2633: : 469it [00:01, 370.46it/s]  \n",
      "=> task: 1/10 | epoch: 14/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.2576 / ewc: 0.0 / total: 0.2576: : 469it [00:01, 369.94it/s] \n",
      "=> task: 1/10 | epoch: 15/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.2525 / ewc: 0.0 / total: 0.2525: : 469it [00:01, 365.67it/s]  \n",
      "=> task: 1/10 | epoch: 16/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.2479 / ewc: 0.0 / total: 0.2479: : 469it [00:01, 368.84it/s] \n",
      "=> task: 1/10 | epoch: 17/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.244 / ewc: 0.0 / total: 0.244: : 469it [00:01, 378.20it/s]    \n",
      "=> task: 1/10 | epoch: 18/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.2401 / ewc: 0.0 / total: 0.2401: : 469it [00:01, 375.37it/s] \n",
      "=> task: 1/10 | epoch: 19/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.2364 / ewc: 0.0 / total: 0.2364: : 469it [00:01, 368.01it/s]  \n",
      "=> task: 1/10 | epoch: 20/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.2328 / ewc: 0.0 / total: 0.2328: : 469it [00:01, 364.44it/s]  \n",
      "=> task: 1/10 | epoch: 21/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.2292 / ewc: 0.0 / total: 0.2292: : 469it [00:01, 370.92it/s]  \n",
      "=> task: 1/10 | epoch: 22/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.2257 / ewc: 0.0 / total: 0.2257: : 469it [00:01, 371.62it/s]  \n",
      "=> task: 1/10 | epoch: 23/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.2228 / ewc: 0.0 / total: 0.2228: : 469it [00:01, 360.39it/s]  \n",
      "=> task: 1/10 | epoch: 24/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.2199 / ewc: 0.0 / total: 0.2199: : 469it [00:01, 365.99it/s]  \n",
      "=> task: 1/10 | epoch: 25/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.217 / ewc: 0.0 / total: 0.217: : 469it [00:01, 361.51it/s]    \n",
      "=> task: 1/10 | epoch: 26/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.2146 / ewc: 0.0 / total: 0.2146: : 469it [00:01, 356.68it/s]  \n",
      "=> task: 1/10 | epoch: 27/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.2122 / ewc: 0.0 / total: 0.2122: : 469it [00:01, 358.84it/s]  \n",
      "=> task: 1/10 | epoch: 28/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.2099 / ewc: 0.0 / total: 0.2099: : 469it [00:01, 370.78it/s]  \n",
      "=> task: 1/10 | epoch: 29/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.208 / ewc: 0.0 / total: 0.208: : 469it [00:01, 370.03it/s]    \n",
      "=> task: 1/10 | epoch: 30/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.2059 / ewc: 0.0 / total: 0.2059: : 469it [00:01, 358.06it/s]  \n",
      "=> task: 1/10 | epoch: 31/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.2037 / ewc: 0.0 / total: 0.2037: : 469it [00:01, 374.22it/s]  \n",
      "=> task: 1/10 | epoch: 32/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.2015 / ewc: 0.0 / total: 0.2015: : 469it [00:01, 370.50it/s]  \n",
      "=> task: 1/10 | epoch: 33/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1999 / ewc: 0.0 / total: 0.1999: : 469it [00:01, 360.93it/s] \n",
      "=> task: 1/10 | epoch: 34/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1978 / ewc: 0.0 / total: 0.1978: : 469it [00:01, 369.15it/s] \n",
      "=> task: 1/10 | epoch: 35/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1957 / ewc: 0.0 / total: 0.1957: : 469it [00:01, 349.97it/s] \n",
      "=> task: 1/10 | epoch: 36/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.194 / ewc: 0.0 / total: 0.194: : 469it [00:01, 366.97it/s]   \n",
      "=> task: 1/10 | epoch: 37/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1919 / ewc: 0.0 / total: 0.1919: : 469it [00:01, 365.43it/s] \n",
      "=> task: 1/10 | epoch: 38/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1899 / ewc: 0.0 / total: 0.1899: : 469it [00:01, 364.66it/s] \n",
      "=> task: 1/10 | epoch: 39/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1876 / ewc: 0.0 / total: 0.1876: : 469it [00:01, 375.51it/s] \n",
      "=> task: 1/10 | epoch: 40/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1858 / ewc: 0.0 / total: 0.1858: : 469it [00:01, 369.48it/s] \n",
      "=> task: 1/10 | epoch: 41/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1839 / ewc: 0.0 / total: 0.1839: : 469it [00:01, 367.43it/s] \n",
      "=> task: 1/10 | epoch: 42/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1819 / ewc: 0.0 / total: 0.1819: : 469it [00:01, 373.06it/s] \n",
      "=> task: 1/10 | epoch: 43/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.18 / ewc: 0.0 / total: 0.18: : 469it [00:01, 369.63it/s]     \n",
      "=> task: 1/10 | epoch: 44/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1777 / ewc: 0.0 / total: 0.1777: : 469it [00:01, 363.57it/s] \n",
      "=> task: 1/10 | epoch: 45/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1758 / ewc: 0.0 / total: 0.1758: : 469it [00:01, 368.27it/s] \n",
      "=> task: 1/10 | epoch: 46/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1738 / ewc: 0.0 / total: 0.1738: : 469it [00:01, 368.55it/s] \n",
      "=> task: 1/10 | epoch: 47/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1718 / ewc: 0.0 / total: 0.1718: : 469it [00:01, 367.84it/s] \n",
      "=> task: 1/10 | epoch: 48/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1698 / ewc: 0.0 / total: 0.1698: : 469it [00:01, 368.26it/s] \n",
      "=> task: 1/10 | epoch: 49/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1679 / ewc: 0.0 / total: 0.1679: : 469it [00:01, 368.71it/s] \n",
      "=> task: 1/10 | epoch: 50/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1659 / ewc: 0.0 / total: 0.1659: : 469it [00:01, 362.80it/s] \n",
      "=> task: 1/10 | epoch: 51/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1641 / ewc: 0.0 / total: 0.1641: : 469it [00:01, 354.16it/s] \n",
      "=> task: 1/10 | epoch: 52/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.162 / ewc: 0.0 / total: 0.162: : 469it [00:01, 371.49it/s]   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> task: 1/10 | epoch: 53/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1604 / ewc: 0.0 / total: 0.1604: : 469it [00:01, 376.03it/s] \n",
      "=> task: 1/10 | epoch: 54/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1587 / ewc: 0.0 / total: 0.1587: : 469it [00:01, 380.58it/s] \n",
      "=> task: 1/10 | epoch: 55/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1569 / ewc: 0.0 / total: 0.1569: : 469it [00:01, 377.38it/s] \n",
      "=> task: 1/10 | epoch: 56/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1551 / ewc: 0.0 / total: 0.1551: : 469it [00:01, 371.66it/s] \n",
      "=> task: 1/10 | epoch: 57/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1536 / ewc: 0.0 / total: 0.1536: : 469it [00:01, 364.30it/s] \n",
      "=> task: 1/10 | epoch: 58/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1516 / ewc: 0.0 / total: 0.1516: : 469it [00:01, 362.77it/s] \n",
      "=> task: 1/10 | epoch: 59/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.15 / ewc: 0.0 / total: 0.15: : 469it [00:01, 384.80it/s]     \n",
      "=> task: 1/10 | epoch: 60/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.148 / ewc: 0.0 / total: 0.148: : 469it [00:01, 372.79it/s]   \n",
      "=> task: 2/10 | epoch: 1/60 | progress: [60032/60000] (100%) | prec: 0.9271 | loss => ce: 0.3176 / ewc: 0.0 / total: 0.3176: : 469it [00:01, 378.38it/s]  \n",
      "=> task: 2/10 | epoch: 2/60 | progress: [60032/60000] (100%) | prec: 0.9583 | loss => ce: 0.2616 / ewc: 0.0 / total: 0.2616: : 469it [00:01, 380.52it/s] \n",
      "=> task: 2/10 | epoch: 3/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.2366 / ewc: 0.0 / total: 0.2366: : 469it [00:01, 370.44it/s] \n",
      "=> task: 2/10 | epoch: 4/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.222 / ewc: 0.0 / total: 0.222: : 469it [00:01, 384.75it/s]   \n",
      "=> task: 2/10 | epoch: 5/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.21 / ewc: 0.0 / total: 0.21: : 469it [00:01, 374.76it/s]      \n",
      "=> task: 2/10 | epoch: 6/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.201 / ewc: 0.0 / total: 0.201: : 469it [00:01, 375.76it/s]    \n",
      "=> task: 2/10 | epoch: 7/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.1942 / ewc: 0.0 / total: 0.1942: : 469it [00:01, 364.25it/s] \n",
      "=> task: 2/10 | epoch: 8/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.1885 / ewc: 0.0 / total: 0.1885: : 469it [00:01, 378.51it/s] \n",
      "=> task: 2/10 | epoch: 9/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1843 / ewc: 0.0 / total: 0.1843: : 469it [00:01, 373.73it/s] \n",
      "=> task: 2/10 | epoch: 10/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1801 / ewc: 0.0 / total: 0.1801: : 469it [00:01, 365.42it/s] \n",
      "=> task: 2/10 | epoch: 11/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1769 / ewc: 0.0 / total: 0.1769: : 469it [00:01, 373.93it/s] \n",
      "=> task: 2/10 | epoch: 12/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1728 / ewc: 0.0 / total: 0.1728: : 469it [00:01, 381.60it/s] \n",
      "=> task: 2/10 | epoch: 13/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1693 / ewc: 0.0 / total: 0.1693: : 469it [00:01, 373.16it/s] \n",
      "=> task: 2/10 | epoch: 14/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1656 / ewc: 0.0 / total: 0.1656: : 469it [00:01, 384.20it/s] \n",
      "=> task: 2/10 | epoch: 15/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1626 / ewc: 0.0 / total: 0.1626: : 469it [00:01, 383.73it/s] \n",
      "=> task: 2/10 | epoch: 16/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1595 / ewc: 0.0 / total: 0.1595: : 469it [00:01, 381.33it/s] \n",
      "=> task: 2/10 | epoch: 17/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.157 / ewc: 0.0 / total: 0.157: : 469it [00:01, 372.64it/s]   \n",
      "=> task: 2/10 | epoch: 18/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1546 / ewc: 0.0 / total: 0.1546: : 469it [00:01, 379.86it/s] \n",
      "=> task: 2/10 | epoch: 19/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1514 / ewc: 0.0 / total: 0.1514: : 469it [00:01, 369.20it/s] \n",
      "=> task: 2/10 | epoch: 20/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1488 / ewc: 0.0 / total: 0.1488: : 469it [00:01, 374.20it/s] \n",
      "=> task: 2/10 | epoch: 21/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1462 / ewc: 0.0 / total: 0.1462: : 469it [00:01, 378.91it/s] \n",
      "=> task: 2/10 | epoch: 22/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1434 / ewc: 0.0 / total: 0.1434: : 469it [00:01, 377.16it/s] \n",
      "=> task: 2/10 | epoch: 23/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1405 / ewc: 0.0 / total: 0.1405: : 469it [00:01, 370.17it/s] \n",
      "=> task: 2/10 | epoch: 24/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1382 / ewc: 0.0 / total: 0.1382: : 469it [00:01, 372.96it/s] \n",
      "=> task: 2/10 | epoch: 25/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1353 / ewc: 0.0 / total: 0.1353: : 469it [00:01, 375.15it/s] \n",
      "=> task: 2/10 | epoch: 26/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1325 / ewc: 0.0 / total: 0.1325: : 469it [00:01, 371.36it/s] \n",
      "=> task: 2/10 | epoch: 27/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.13 / ewc: 0.0 / total: 0.13: : 469it [00:01, 386.43it/s]     \n",
      "=> task: 2/10 | epoch: 28/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1271 / ewc: 0.0 / total: 0.1271: : 469it [00:01, 373.12it/s] \n",
      "=> task: 2/10 | epoch: 29/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1243 / ewc: 0.0 / total: 0.1243: : 469it [00:01, 373.30it/s] \n",
      "=> task: 2/10 | epoch: 30/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1211 / ewc: 0.0 / total: 0.1211: : 469it [00:01, 376.56it/s] \n",
      "=> task: 2/10 | epoch: 31/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1181 / ewc: 0.0 / total: 0.1181: : 469it [00:01, 372.41it/s] \n",
      "=> task: 2/10 | epoch: 32/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1155 / ewc: 0.0 / total: 0.1155: : 469it [00:01, 375.73it/s] \n",
      "=> task: 2/10 | epoch: 33/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1128 / ewc: 0.0 / total: 0.1128: : 469it [00:01, 386.47it/s] \n",
      "=> task: 2/10 | epoch: 34/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1099 / ewc: 0.0 / total: 0.1099: : 469it [00:01, 365.77it/s] \n",
      "=> task: 2/10 | epoch: 35/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1072 / ewc: 0.0 / total: 0.1072: : 469it [00:01, 375.38it/s] \n",
      "=> task: 2/10 | epoch: 36/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1045 / ewc: 0.0 / total: 0.1045: : 469it [00:01, 382.17it/s]  \n",
      "=> task: 2/10 | epoch: 37/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1017 / ewc: 0.0 / total: 0.1017: : 469it [00:01, 377.28it/s]  \n",
      "=> task: 2/10 | epoch: 38/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.09907 / ewc: 0.0 / total: 0.09907: : 469it [00:01, 372.14it/s]\n",
      "=> task: 2/10 | epoch: 39/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.09637 / ewc: 0.0 / total: 0.09637: : 469it [00:01, 373.26it/s]\n",
      "=> task: 2/10 | epoch: 40/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.09316 / ewc: 0.0 / total: 0.09316: : 469it [00:01, 365.61it/s]\n",
      "=> task: 2/10 | epoch: 41/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.09036 / ewc: 0.0 / total: 0.09036: : 469it [00:01, 381.46it/s]\n",
      "=> task: 2/10 | epoch: 42/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.08766 / ewc: 0.0 / total: 0.08766: : 469it [00:01, 377.86it/s]\n",
      "=> task: 2/10 | epoch: 43/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.08484 / ewc: 0.0 / total: 0.08484: : 469it [00:01, 382.83it/s]\n",
      "=> task: 2/10 | epoch: 44/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.08197 / ewc: 0.0 / total: 0.08197: : 469it [00:01, 371.80it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> task: 2/10 | epoch: 45/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.07956 / ewc: 0.0 / total: 0.07956: : 469it [00:01, 364.93it/s] \n",
      "=> task: 2/10 | epoch: 46/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.07623 / ewc: 0.0 / total: 0.07623: : 469it [00:01, 383.83it/s]\n",
      "=> task: 2/10 | epoch: 47/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.07377 / ewc: 0.0 / total: 0.07377: : 469it [00:01, 375.03it/s]\n",
      "=> task: 2/10 | epoch: 48/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.07092 / ewc: 0.0 / total: 0.07092: : 469it [00:01, 380.89it/s]\n",
      "=> task: 2/10 | epoch: 49/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.06836 / ewc: 0.0 / total: 0.06836: : 469it [00:01, 370.96it/s]\n",
      "=> task: 2/10 | epoch: 50/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.06547 / ewc: 0.0 / total: 0.06547: : 469it [00:01, 390.27it/s]\n",
      "=> task: 2/10 | epoch: 51/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.06273 / ewc: 0.0 / total: 0.06273: : 469it [00:01, 379.49it/s]\n",
      "=> task: 2/10 | epoch: 52/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.05993 / ewc: 0.0 / total: 0.05993: : 469it [00:01, 375.90it/s]\n",
      "=> task: 2/10 | epoch: 53/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.05723 / ewc: 0.0 / total: 0.05723: : 469it [00:01, 372.97it/s]\n",
      "=> task: 2/10 | epoch: 54/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.05467 / ewc: 0.0 / total: 0.05467: : 469it [00:01, 376.15it/s]\n",
      "=> task: 2/10 | epoch: 55/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.05201 / ewc: 0.0 / total: 0.05201: : 469it [00:01, 378.32it/s]\n",
      "=> task: 2/10 | epoch: 56/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.04928 / ewc: 0.0 / total: 0.04928: : 469it [00:01, 379.94it/s]\n",
      "=> task: 2/10 | epoch: 57/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.04665 / ewc: 0.0 / total: 0.04665: : 469it [00:01, 377.48it/s]\n",
      "=> task: 2/10 | epoch: 58/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.04428 / ewc: 0.0 / total: 0.04428: : 469it [00:01, 374.85it/s]\n",
      "=> task: 2/10 | epoch: 59/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.04169 / ewc: 0.0 / total: 0.04169: : 469it [00:01, 368.48it/s]\n",
      "=> task: 2/10 | epoch: 60/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.03901 / ewc: 0.0 / total: 0.03901: : 469it [00:01, 373.33it/s] \n",
      "=> task: 3/10 | epoch: 1/60 | progress: [60032/60000] (100%) | prec: 0.9688 | loss => ce: 0.2595 / ewc: 0.0 / total: 0.2595: : 469it [00:01, 367.77it/s] \n",
      "=> task: 3/10 | epoch: 2/60 | progress: [60032/60000] (100%) | prec: 0.9688 | loss => ce: 0.2266 / ewc: 0.0 / total: 0.2266: : 469it [00:01, 371.79it/s]  \n",
      "=> task: 3/10 | epoch: 3/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.2131 / ewc: 0.0 / total: 0.2131: : 469it [00:01, 381.71it/s]  \n",
      "=> task: 3/10 | epoch: 4/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.2032 / ewc: 0.0 / total: 0.2032: : 469it [00:01, 370.71it/s]  \n",
      "=> task: 3/10 | epoch: 5/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.1969 / ewc: 0.0 / total: 0.1969: : 469it [00:01, 373.12it/s] \n",
      "=> task: 3/10 | epoch: 6/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1915 / ewc: 0.0 / total: 0.1915: : 469it [00:01, 387.39it/s] \n",
      "=> task: 3/10 | epoch: 7/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1865 / ewc: 0.0 / total: 0.1865: : 469it [00:01, 373.23it/s] \n",
      "=> task: 3/10 | epoch: 8/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1838 / ewc: 0.0 / total: 0.1838: : 469it [00:01, 373.02it/s] \n",
      "=> task: 3/10 | epoch: 9/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1793 / ewc: 0.0 / total: 0.1793: : 469it [00:01, 381.74it/s] \n",
      "=> task: 3/10 | epoch: 10/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.175 / ewc: 0.0 / total: 0.175: : 469it [00:01, 369.56it/s]   \n",
      "=> task: 3/10 | epoch: 11/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1707 / ewc: 0.0 / total: 0.1707: : 469it [00:01, 378.07it/s] \n",
      "=> task: 3/10 | epoch: 12/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1679 / ewc: 0.0 / total: 0.1679: : 469it [00:01, 373.20it/s] \n",
      "=> task: 3/10 | epoch: 13/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.164 / ewc: 0.0 / total: 0.164: : 469it [00:01, 365.94it/s]   \n",
      "=> task: 3/10 | epoch: 14/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1606 / ewc: 0.0 / total: 0.1606: : 469it [00:01, 367.46it/s] \n",
      "=> task: 3/10 | epoch: 15/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1572 / ewc: 0.0 / total: 0.1572: : 469it [00:01, 380.73it/s] \n",
      "=> task: 3/10 | epoch: 16/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.154 / ewc: 0.0 / total: 0.154: : 469it [00:01, 368.46it/s]   \n",
      "=> task: 3/10 | epoch: 17/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.152 / ewc: 0.0 / total: 0.152: : 469it [00:01, 376.63it/s]   \n",
      "=> task: 3/10 | epoch: 18/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1476 / ewc: 0.0 / total: 0.1476: : 469it [00:01, 361.32it/s] \n",
      "=> task: 3/10 | epoch: 19/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1442 / ewc: 0.0 / total: 0.1442: : 469it [00:01, 379.45it/s] \n",
      "=> task: 3/10 | epoch: 20/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1411 / ewc: 0.0 / total: 0.1411: : 469it [00:01, 382.00it/s] \n",
      "=> task: 3/10 | epoch: 21/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1376 / ewc: 0.0 / total: 0.1376: : 469it [00:01, 350.55it/s] \n",
      "=> task: 3/10 | epoch: 22/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.135 / ewc: 0.0 / total: 0.135: : 469it [00:01, 368.85it/s]   \n",
      "=> task: 3/10 | epoch: 23/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1311 / ewc: 0.0 / total: 0.1311: : 469it [00:01, 379.38it/s] \n",
      "=> task: 3/10 | epoch: 24/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1282 / ewc: 0.0 / total: 0.1282: : 469it [00:01, 380.87it/s]  \n",
      "=> task: 3/10 | epoch: 25/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1233 / ewc: 0.0 / total: 0.1233: : 469it [00:01, 377.80it/s]  \n",
      "=> task: 3/10 | epoch: 26/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1192 / ewc: 0.0 / total: 0.1192: : 469it [00:01, 373.15it/s] \n",
      "=> task: 3/10 | epoch: 27/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.116 / ewc: 0.0 / total: 0.116: : 469it [00:01, 369.15it/s]    \n",
      "=> task: 3/10 | epoch: 28/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1114 / ewc: 0.0 / total: 0.1114: : 469it [00:01, 369.97it/s] \n",
      "=> task: 3/10 | epoch: 29/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1074 / ewc: 0.0 / total: 0.1074: : 469it [00:01, 380.83it/s]  \n",
      "=> task: 3/10 | epoch: 30/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1036 / ewc: 0.0 / total: 0.1036: : 469it [00:01, 380.58it/s] \n",
      "=> task: 3/10 | epoch: 31/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.09901 / ewc: 0.0 / total: 0.09901: : 469it [00:01, 375.29it/s]\n",
      "=> task: 3/10 | epoch: 32/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.095 / ewc: 0.0 / total: 0.095: : 469it [00:01, 380.09it/s]    \n",
      "=> task: 3/10 | epoch: 33/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.09145 / ewc: 0.0 / total: 0.09145: : 469it [00:01, 371.92it/s]\n",
      "=> task: 3/10 | epoch: 34/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.0872 / ewc: 0.0 / total: 0.0872: : 469it [00:01, 373.95it/s]  \n",
      "=> task: 3/10 | epoch: 35/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.08316 / ewc: 0.0 / total: 0.08316: : 469it [00:01, 384.39it/s]\n",
      "=> task: 3/10 | epoch: 36/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.07892 / ewc: 0.0 / total: 0.07892: : 469it [00:01, 377.60it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> task: 3/10 | epoch: 37/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.07541 / ewc: 0.0 / total: 0.07541: : 469it [00:01, 392.41it/s]\n",
      "=> task: 3/10 | epoch: 38/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.07092 / ewc: 0.0 / total: 0.07092: : 469it [00:01, 375.77it/s]\n",
      "=> task: 3/10 | epoch: 39/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.06728 / ewc: 0.0 / total: 0.06728: : 469it [00:01, 378.55it/s]\n",
      "=> task: 3/10 | epoch: 40/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.06314 / ewc: 0.0 / total: 0.06314: : 469it [00:01, 388.09it/s]\n",
      "=> task: 3/10 | epoch: 41/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.05882 / ewc: 0.0 / total: 0.05882: : 469it [00:01, 378.14it/s] \n",
      "=> task: 3/10 | epoch: 42/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.05517 / ewc: 0.0 / total: 0.05517: : 469it [00:01, 372.14it/s] \n",
      "=> task: 3/10 | epoch: 43/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.05086 / ewc: 0.0 / total: 0.05086: : 469it [00:01, 363.90it/s]\n",
      "=> task: 3/10 | epoch: 44/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.04697 / ewc: 0.0 / total: 0.04697: : 469it [00:01, 369.62it/s]\n",
      "=> task: 3/10 | epoch: 45/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.04292 / ewc: 0.0 / total: 0.04292: : 469it [00:01, 379.03it/s]\n",
      "=> task: 3/10 | epoch: 46/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.03883 / ewc: 0.0 / total: 0.03883: : 469it [00:01, 385.88it/s]\n",
      "=> task: 3/10 | epoch: 47/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.03463 / ewc: 0.0 / total: 0.03463: : 469it [00:01, 380.25it/s] \n",
      "=> task: 3/10 | epoch: 48/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.03141 / ewc: 0.0 / total: 0.03141: : 469it [00:01, 388.42it/s] \n",
      "=> task: 3/10 | epoch: 49/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.02784 / ewc: 0.0 / total: 0.02784: : 469it [00:01, 367.39it/s] \n",
      "=> task: 3/10 | epoch: 50/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.02465 / ewc: 0.0 / total: 0.02465: : 469it [00:01, 368.37it/s] \n",
      "=> task: 3/10 | epoch: 51/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.02196 / ewc: 0.0 / total: 0.02196: : 469it [00:01, 358.77it/s] \n",
      "=> task: 3/10 | epoch: 52/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01928 / ewc: 0.0 / total: 0.01928: : 469it [00:01, 364.13it/s] \n",
      "=> task: 3/10 | epoch: 53/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01771 / ewc: 0.0 / total: 0.01771: : 469it [00:01, 362.05it/s] \n",
      "=> task: 3/10 | epoch: 54/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01565 / ewc: 0.0 / total: 0.01565: : 469it [00:01, 374.66it/s] \n",
      "=> task: 3/10 | epoch: 55/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01449 / ewc: 0.0 / total: 0.01449: : 469it [00:01, 363.03it/s] \n",
      "=> task: 3/10 | epoch: 56/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01302 / ewc: 0.0 / total: 0.01302: : 469it [00:01, 367.47it/s] \n",
      "=> task: 3/10 | epoch: 57/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01228 / ewc: 0.0 / total: 0.01228: : 469it [00:01, 372.24it/s] \n",
      "=> task: 3/10 | epoch: 58/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01128 / ewc: 0.0 / total: 0.01128: : 469it [00:01, 380.43it/s]\n",
      "=> task: 3/10 | epoch: 59/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.01047 / ewc: 0.0 / total: 0.01047: : 469it [00:01, 380.74it/s]   \n",
      "=> task: 3/10 | epoch: 60/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.009969 / ewc: 0.0 / total: 0.009969: : 469it [00:01, 379.40it/s] \n",
      "=> task: 4/10 | epoch: 1/60 | progress: [60032/60000] (100%) | prec: 0.9688 | loss => ce: 0.2414 / ewc: 0.0 / total: 0.2414: : 469it [00:01, 366.15it/s]  \n",
      "=> task: 4/10 | epoch: 2/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.2096 / ewc: 0.0 / total: 0.2096: : 469it [00:01, 369.96it/s]  \n",
      "=> task: 4/10 | epoch: 3/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.2026 / ewc: 0.0 / total: 0.2026: : 469it [00:01, 372.89it/s] \n",
      "=> task: 4/10 | epoch: 4/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1972 / ewc: 0.0 / total: 0.1972: : 469it [00:01, 374.82it/s] \n",
      "=> task: 4/10 | epoch: 5/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1897 / ewc: 0.0 / total: 0.1897: : 469it [00:01, 390.47it/s] \n",
      "=> task: 4/10 | epoch: 6/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1832 / ewc: 0.0 / total: 0.1832: : 469it [00:01, 386.53it/s] \n",
      "=> task: 4/10 | epoch: 7/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1776 / ewc: 0.0 / total: 0.1776: : 469it [00:01, 366.53it/s] \n",
      "=> task: 4/10 | epoch: 8/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1707 / ewc: 0.0 / total: 0.1707: : 469it [00:01, 391.15it/s] \n",
      "=> task: 4/10 | epoch: 9/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1674 / ewc: 0.0 / total: 0.1674: : 469it [00:01, 383.93it/s] \n",
      "=> task: 4/10 | epoch: 10/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1619 / ewc: 0.0 / total: 0.1619: : 469it [00:01, 367.55it/s] \n",
      "=> task: 4/10 | epoch: 11/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1572 / ewc: 0.0 / total: 0.1572: : 469it [00:01, 374.14it/s] \n",
      "=> task: 4/10 | epoch: 12/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1512 / ewc: 0.0 / total: 0.1512: : 469it [00:01, 399.63it/s] \n",
      "=> task: 4/10 | epoch: 13/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1472 / ewc: 0.0 / total: 0.1472: : 469it [00:01, 377.25it/s]   \n",
      "=> task: 4/10 | epoch: 14/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1424 / ewc: 0.0 / total: 0.1424: : 469it [00:01, 369.43it/s]   \n",
      "=> task: 4/10 | epoch: 15/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1382 / ewc: 0.0 / total: 0.1382: : 469it [00:01, 386.20it/s]   \n",
      "=> task: 4/10 | epoch: 16/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1327 / ewc: 0.0 / total: 0.1327: : 469it [00:01, 371.84it/s]   \n",
      "=> task: 4/10 | epoch: 17/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1278 / ewc: 0.0 / total: 0.1278: : 469it [00:01, 380.42it/s]   \n",
      "=> task: 4/10 | epoch: 18/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.124 / ewc: 0.0 / total: 0.124: : 469it [00:01, 375.30it/s]     \n",
      "=> task: 4/10 | epoch: 19/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1183 / ewc: 0.0 / total: 0.1183: : 469it [00:01, 377.26it/s] \n",
      "=> task: 4/10 | epoch: 20/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1128 / ewc: 0.0 / total: 0.1128: : 469it [00:01, 381.01it/s]  \n",
      "=> task: 4/10 | epoch: 21/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1072 / ewc: 0.0 / total: 0.1072: : 469it [00:01, 380.55it/s] \n",
      "=> task: 4/10 | epoch: 22/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1024 / ewc: 0.0 / total: 0.1024: : 469it [00:01, 379.60it/s]  \n",
      "=> task: 4/10 | epoch: 23/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.09784 / ewc: 0.0 / total: 0.09784: : 469it [00:01, 374.14it/s]\n",
      "=> task: 4/10 | epoch: 24/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.09318 / ewc: 0.0 / total: 0.09318: : 469it [00:01, 371.92it/s]\n",
      "=> task: 4/10 | epoch: 25/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.08788 / ewc: 0.0 / total: 0.08788: : 469it [00:01, 362.34it/s]\n",
      "=> task: 4/10 | epoch: 26/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.08303 / ewc: 0.0 / total: 0.08303: : 469it [00:01, 355.46it/s] \n",
      "=> task: 4/10 | epoch: 27/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.07707 / ewc: 0.0 / total: 0.07707: : 469it [00:01, 380.79it/s] \n",
      "=> task: 4/10 | epoch: 28/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.07331 / ewc: 0.0 / total: 0.07331: : 469it [00:01, 368.35it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> task: 4/10 | epoch: 29/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.06703 / ewc: 0.0 / total: 0.06703: : 469it [00:01, 370.07it/s]\n",
      "=> task: 4/10 | epoch: 30/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.06139 / ewc: 0.0 / total: 0.06139: : 469it [00:01, 374.89it/s]\n",
      "=> task: 4/10 | epoch: 31/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.05669 / ewc: 0.0 / total: 0.05669: : 469it [00:01, 379.64it/s] \n",
      "=> task: 4/10 | epoch: 32/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.05162 / ewc: 0.0 / total: 0.05162: : 469it [00:01, 366.47it/s] \n",
      "=> task: 4/10 | epoch: 33/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.04709 / ewc: 0.0 / total: 0.04709: : 469it [00:01, 380.38it/s] \n",
      "=> task: 4/10 | epoch: 34/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.04212 / ewc: 0.0 / total: 0.04212: : 469it [00:01, 382.29it/s]\n",
      "=> task: 4/10 | epoch: 35/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.03752 / ewc: 0.0 / total: 0.03752: : 469it [00:01, 379.08it/s] \n",
      "=> task: 4/10 | epoch: 36/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.03323 / ewc: 0.0 / total: 0.03323: : 469it [00:01, 371.78it/s] \n",
      "=> task: 4/10 | epoch: 37/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.02865 / ewc: 0.0 / total: 0.02865: : 469it [00:01, 386.70it/s]\n",
      "=> task: 4/10 | epoch: 38/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.02599 / ewc: 0.0 / total: 0.02599: : 469it [00:01, 381.45it/s] \n",
      "=> task: 4/10 | epoch: 39/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.02176 / ewc: 0.0 / total: 0.02176: : 469it [00:01, 372.73it/s] \n",
      "=> task: 4/10 | epoch: 40/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01913 / ewc: 0.0 / total: 0.01913: : 469it [00:01, 368.55it/s] \n",
      "=> task: 4/10 | epoch: 41/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01691 / ewc: 0.0 / total: 0.01691: : 469it [00:01, 370.87it/s]\n",
      "=> task: 4/10 | epoch: 42/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01499 / ewc: 0.0 / total: 0.01499: : 469it [00:01, 378.57it/s]\n",
      "=> task: 4/10 | epoch: 43/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01404 / ewc: 0.0 / total: 0.01404: : 469it [00:01, 371.45it/s]\n",
      "=> task: 4/10 | epoch: 44/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01225 / ewc: 0.0 / total: 0.01225: : 469it [00:01, 380.65it/s] \n",
      "=> task: 4/10 | epoch: 45/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.01131 / ewc: 0.0 / total: 0.01131: : 469it [00:01, 376.44it/s]    \n",
      "=> task: 4/10 | epoch: 46/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.01059 / ewc: 0.0 / total: 0.01059: : 469it [00:01, 364.09it/s]    \n",
      "=> task: 4/10 | epoch: 47/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.009887 / ewc: 0.0 / total: 0.009887: : 469it [00:01, 380.58it/s]  \n",
      "=> task: 4/10 | epoch: 48/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.009131 / ewc: 0.0 / total: 0.009131: : 469it [00:01, 375.98it/s]  \n",
      "=> task: 4/10 | epoch: 49/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.008711 / ewc: 0.0 / total: 0.008711: : 469it [00:01, 369.59it/s]  \n",
      "=> task: 4/10 | epoch: 50/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.008181 / ewc: 0.0 / total: 0.008181: : 469it [00:01, 372.57it/s]  \n",
      "=> task: 4/10 | epoch: 51/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.007896 / ewc: 0.0 / total: 0.007896: : 469it [00:01, 376.91it/s] \n",
      "=> task: 4/10 | epoch: 52/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.007495 / ewc: 0.0 / total: 0.007495: : 469it [00:01, 374.87it/s] \n",
      "=> task: 4/10 | epoch: 53/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.007005 / ewc: 0.0 / total: 0.007005: : 469it [00:01, 377.61it/s] \n",
      "=> task: 4/10 | epoch: 54/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.006884 / ewc: 0.0 / total: 0.006884: : 469it [00:01, 381.75it/s] \n",
      "=> task: 4/10 | epoch: 55/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.006555 / ewc: 0.0 / total: 0.006555: : 469it [00:01, 369.36it/s] \n",
      "=> task: 4/10 | epoch: 56/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.00634 / ewc: 0.0 / total: 0.00634: : 469it [00:01, 368.60it/s]   \n",
      "=> task: 4/10 | epoch: 57/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.006201 / ewc: 0.0 / total: 0.006201: : 469it [00:01, 380.67it/s] \n",
      "=> task: 4/10 | epoch: 58/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.005905 / ewc: 0.0 / total: 0.005905: : 469it [00:01, 373.76it/s]  \n",
      "=> task: 4/10 | epoch: 59/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.005737 / ewc: 0.0 / total: 0.005737: : 469it [00:01, 374.39it/s]  \n",
      "=> task: 4/10 | epoch: 60/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.005602 / ewc: 0.0 / total: 0.005602: : 469it [00:01, 376.96it/s]  \n",
      "=> task: 5/10 | epoch: 1/60 | progress: [60032/60000] (100%) | prec: 0.9479 | loss => ce: 0.2733 / ewc: 0.0 / total: 0.2733: : 469it [00:01, 386.04it/s]  \n",
      "=> task: 5/10 | epoch: 2/60 | progress: [60032/60000] (100%) | prec: 0.9583 | loss => ce: 0.2378 / ewc: 0.0 / total: 0.2378: : 469it [00:01, 382.67it/s] \n",
      "=> task: 5/10 | epoch: 3/60 | progress: [60032/60000] (100%) | prec: 0.9688 | loss => ce: 0.2232 / ewc: 0.0 / total: 0.2232: : 469it [00:01, 382.37it/s] \n",
      "=> task: 5/10 | epoch: 4/60 | progress: [60032/60000] (100%) | prec: 0.9688 | loss => ce: 0.2159 / ewc: 0.0 / total: 0.2159: : 469it [00:01, 369.54it/s] \n",
      "=> task: 5/10 | epoch: 5/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.2076 / ewc: 0.0 / total: 0.2076: : 469it [00:01, 374.87it/s] \n",
      "=> task: 5/10 | epoch: 6/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.2013 / ewc: 0.0 / total: 0.2013: : 469it [00:01, 384.45it/s] \n",
      "=> task: 5/10 | epoch: 7/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.1948 / ewc: 0.0 / total: 0.1948: : 469it [00:01, 386.42it/s] \n",
      "=> task: 5/10 | epoch: 8/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.1892 / ewc: 0.0 / total: 0.1892: : 469it [00:01, 389.95it/s] \n",
      "=> task: 5/10 | epoch: 9/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1839 / ewc: 0.0 / total: 0.1839: : 469it [00:01, 383.74it/s] \n",
      "=> task: 5/10 | epoch: 10/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1781 / ewc: 0.0 / total: 0.1781: : 469it [00:01, 380.87it/s] \n",
      "=> task: 5/10 | epoch: 11/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1749 / ewc: 0.0 / total: 0.1749: : 469it [00:01, 378.28it/s] \n",
      "=> task: 5/10 | epoch: 12/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1698 / ewc: 0.0 / total: 0.1698: : 469it [00:01, 390.07it/s] \n",
      "=> task: 5/10 | epoch: 13/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1657 / ewc: 0.0 / total: 0.1657: : 469it [00:01, 383.55it/s] \n",
      "=> task: 5/10 | epoch: 14/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1606 / ewc: 0.0 / total: 0.1606: : 469it [00:01, 375.84it/s] \n",
      "=> task: 5/10 | epoch: 15/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1555 / ewc: 0.0 / total: 0.1555: : 469it [00:01, 378.04it/s] \n",
      "=> task: 5/10 | epoch: 16/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1504 / ewc: 0.0 / total: 0.1504: : 469it [00:01, 369.66it/s]  \n",
      "=> task: 5/10 | epoch: 17/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1447 / ewc: 0.0 / total: 0.1447: : 469it [00:01, 372.30it/s]  \n",
      "=> task: 5/10 | epoch: 18/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1392 / ewc: 0.0 / total: 0.1392: : 469it [00:01, 383.78it/s]  \n",
      "=> task: 5/10 | epoch: 19/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1338 / ewc: 0.0 / total: 0.1338: : 469it [00:01, 381.45it/s]  \n",
      "=> task: 5/10 | epoch: 20/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1285 / ewc: 0.0 / total: 0.1285: : 469it [00:01, 379.84it/s]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> task: 5/10 | epoch: 21/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1221 / ewc: 0.0 / total: 0.1221: : 469it [00:01, 378.59it/s]  \n",
      "=> task: 5/10 | epoch: 22/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.116 / ewc: 0.0 / total: 0.116: : 469it [00:01, 374.87it/s]    \n",
      "=> task: 5/10 | epoch: 23/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.111 / ewc: 0.0 / total: 0.111: : 469it [00:01, 375.76it/s]   \n",
      "=> task: 5/10 | epoch: 24/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1044 / ewc: 0.0 / total: 0.1044: : 469it [00:01, 382.47it/s]   \n",
      "=> task: 5/10 | epoch: 25/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.09882 / ewc: 0.0 / total: 0.09882: : 469it [00:01, 378.92it/s]\n",
      "=> task: 5/10 | epoch: 26/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.09207 / ewc: 0.0 / total: 0.09207: : 469it [00:01, 380.40it/s]\n",
      "=> task: 5/10 | epoch: 27/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.08598 / ewc: 0.0 / total: 0.08598: : 469it [00:01, 380.79it/s]\n",
      "=> task: 5/10 | epoch: 28/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.07987 / ewc: 0.0 / total: 0.07987: : 469it [00:01, 379.64it/s]\n",
      "=> task: 5/10 | epoch: 29/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.07333 / ewc: 0.0 / total: 0.07333: : 469it [00:01, 364.77it/s]\n",
      "=> task: 5/10 | epoch: 30/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.0667 / ewc: 0.0 / total: 0.0667: : 469it [00:01, 373.03it/s]  \n",
      "=> task: 5/10 | epoch: 31/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.0614 / ewc: 0.0 / total: 0.0614: : 469it [00:01, 376.45it/s]  \n",
      "=> task: 5/10 | epoch: 32/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.05494 / ewc: 0.0 / total: 0.05494: : 469it [00:01, 378.34it/s]\n",
      "=> task: 5/10 | epoch: 33/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.04824 / ewc: 0.0 / total: 0.04824: : 469it [00:01, 369.63it/s]\n",
      "=> task: 5/10 | epoch: 34/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.04216 / ewc: 0.0 / total: 0.04216: : 469it [00:01, 366.52it/s] \n",
      "=> task: 5/10 | epoch: 35/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.03655 / ewc: 0.0 / total: 0.03655: : 469it [00:01, 384.35it/s] \n",
      "=> task: 5/10 | epoch: 36/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.03102 / ewc: 0.0 / total: 0.03102: : 469it [00:01, 381.68it/s] \n",
      "=> task: 5/10 | epoch: 37/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.02588 / ewc: 0.0 / total: 0.02588: : 469it [00:01, 369.10it/s] \n",
      "=> task: 5/10 | epoch: 38/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.02155 / ewc: 0.0 / total: 0.02155: : 469it [00:01, 375.98it/s]\n",
      "=> task: 5/10 | epoch: 39/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01806 / ewc: 0.0 / total: 0.01806: : 469it [00:01, 374.05it/s]\n",
      "=> task: 5/10 | epoch: 40/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01593 / ewc: 0.0 / total: 0.01593: : 469it [00:01, 388.56it/s] \n",
      "=> task: 5/10 | epoch: 41/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01369 / ewc: 0.0 / total: 0.01369: : 469it [00:01, 378.70it/s] \n",
      "=> task: 5/10 | epoch: 42/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01208 / ewc: 0.0 / total: 0.01208: : 469it [00:01, 383.18it/s] \n",
      "=> task: 5/10 | epoch: 43/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.01108 / ewc: 0.0 / total: 0.01108: : 469it [00:01, 380.61it/s]   \n",
      "=> task: 5/10 | epoch: 44/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.01011 / ewc: 0.0 / total: 0.01011: : 469it [00:01, 372.13it/s]   \n",
      "=> task: 5/10 | epoch: 45/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.009259 / ewc: 0.0 / total: 0.009259: : 469it [00:01, 374.49it/s] \n",
      "=> task: 5/10 | epoch: 46/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.00861 / ewc: 0.0 / total: 0.00861: : 469it [00:01, 384.68it/s]   \n",
      "=> task: 5/10 | epoch: 47/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.008116 / ewc: 0.0 / total: 0.008116: : 469it [00:01, 364.24it/s] \n",
      "=> task: 5/10 | epoch: 48/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.007741 / ewc: 0.0 / total: 0.007741: : 469it [00:01, 384.57it/s] \n",
      "=> task: 5/10 | epoch: 49/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.007226 / ewc: 0.0 / total: 0.007226: : 469it [00:01, 369.28it/s] \n",
      "=> task: 5/10 | epoch: 50/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.006992 / ewc: 0.0 / total: 0.006992: : 469it [00:01, 377.30it/s] \n",
      "=> task: 5/10 | epoch: 51/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.006543 / ewc: 0.0 / total: 0.006543: : 469it [00:01, 372.86it/s]  \n",
      "=> task: 5/10 | epoch: 52/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.006395 / ewc: 0.0 / total: 0.006395: : 469it [00:01, 372.26it/s]  \n",
      "=> task: 5/10 | epoch: 53/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.006129 / ewc: 0.0 / total: 0.006129: : 469it [00:01, 389.88it/s]  \n",
      "=> task: 5/10 | epoch: 54/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.005813 / ewc: 0.0 / total: 0.005813: : 469it [00:01, 378.17it/s]  \n",
      "=> task: 5/10 | epoch: 55/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.005567 / ewc: 0.0 / total: 0.005567: : 469it [00:01, 386.65it/s]  \n",
      "=> task: 5/10 | epoch: 56/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.005457 / ewc: 0.0 / total: 0.005457: : 469it [00:01, 366.83it/s]  \n",
      "=> task: 5/10 | epoch: 57/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.005212 / ewc: 0.0 / total: 0.005212: : 469it [00:01, 368.68it/s]  \n",
      "=> task: 5/10 | epoch: 58/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.005057 / ewc: 0.0 / total: 0.005057: : 469it [00:01, 366.96it/s]  \n",
      "=> task: 5/10 | epoch: 59/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.004911 / ewc: 0.0 / total: 0.004911: : 469it [00:01, 367.38it/s]  \n",
      "=> task: 5/10 | epoch: 60/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.004768 / ewc: 0.0 / total: 0.004768: : 469it [00:01, 366.45it/s]  \n",
      "=> task: 6/10 | epoch: 1/60 | progress: [60032/60000] (100%) | prec: 0.9479 | loss => ce: 0.2703 / ewc: 0.0 / total: 0.2703: : 469it [00:01, 360.90it/s]  \n",
      "=> task: 6/10 | epoch: 2/60 | progress: [60032/60000] (100%) | prec: 0.9688 | loss => ce: 0.2273 / ewc: 0.0 / total: 0.2273: : 469it [00:01, 367.52it/s]  \n",
      "=> task: 6/10 | epoch: 3/60 | progress: [60032/60000] (100%) | prec: 0.9688 | loss => ce: 0.206 / ewc: 0.0 / total: 0.206: : 469it [00:01, 354.99it/s]   \n",
      "=> task: 6/10 | epoch: 4/60 | progress: [60032/60000] (100%) | prec: 0.9688 | loss => ce: 0.1983 / ewc: 0.0 / total: 0.1983: : 469it [00:01, 366.85it/s] \n",
      "=> task: 6/10 | epoch: 5/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.1877 / ewc: 0.0 / total: 0.1877: : 469it [00:01, 367.50it/s] \n",
      "=> task: 6/10 | epoch: 6/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1767 / ewc: 0.0 / total: 0.1767: : 469it [00:01, 371.61it/s] \n",
      "=> task: 6/10 | epoch: 7/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1694 / ewc: 0.0 / total: 0.1694: : 469it [00:01, 367.77it/s] \n",
      "=> task: 6/10 | epoch: 8/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.161 / ewc: 0.0 / total: 0.161: : 469it [00:01, 362.04it/s]   \n",
      "=> task: 6/10 | epoch: 9/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1537 / ewc: 0.0 / total: 0.1537: : 469it [00:01, 377.30it/s] \n",
      "=> task: 6/10 | epoch: 10/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1463 / ewc: 0.0 / total: 0.1463: : 469it [00:01, 373.19it/s] \n",
      "=> task: 6/10 | epoch: 11/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1396 / ewc: 0.0 / total: 0.1396: : 469it [00:01, 370.96it/s] \n",
      "=> task: 6/10 | epoch: 12/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1335 / ewc: 0.0 / total: 0.1335: : 469it [00:01, 376.59it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> task: 6/10 | epoch: 13/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1288 / ewc: 0.0 / total: 0.1288: : 469it [00:01, 374.31it/s] \n",
      "=> task: 6/10 | epoch: 14/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1239 / ewc: 0.0 / total: 0.1239: : 469it [00:01, 382.44it/s]  \n",
      "=> task: 6/10 | epoch: 15/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1191 / ewc: 0.0 / total: 0.1191: : 469it [00:01, 366.67it/s]  \n",
      "=> task: 6/10 | epoch: 16/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1143 / ewc: 0.0 / total: 0.1143: : 469it [00:01, 371.50it/s]  \n",
      "=> task: 6/10 | epoch: 17/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1094 / ewc: 0.0 / total: 0.1094: : 469it [00:01, 380.25it/s]  \n",
      "=> task: 6/10 | epoch: 18/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1049 / ewc: 0.0 / total: 0.1049: : 469it [00:01, 378.42it/s]  \n",
      "=> task: 6/10 | epoch: 19/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.09884 / ewc: 0.0 / total: 0.09884: : 469it [00:01, 387.10it/s]\n",
      "=> task: 6/10 | epoch: 20/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.09393 / ewc: 0.0 / total: 0.09393: : 469it [00:01, 375.45it/s]\n",
      "=> task: 6/10 | epoch: 21/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.08696 / ewc: 0.0 / total: 0.08696: : 469it [00:01, 378.26it/s]\n",
      "=> task: 6/10 | epoch: 22/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.08184 / ewc: 0.0 / total: 0.08184: : 469it [00:01, 370.37it/s]\n",
      "=> task: 6/10 | epoch: 23/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.07547 / ewc: 0.0 / total: 0.07547: : 469it [00:01, 376.66it/s]\n",
      "=> task: 6/10 | epoch: 24/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.071 / ewc: 0.0 / total: 0.071: : 469it [00:01, 368.89it/s]    \n",
      "=> task: 6/10 | epoch: 25/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.06506 / ewc: 0.0 / total: 0.06506: : 469it [00:01, 372.71it/s]\n",
      "=> task: 6/10 | epoch: 26/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.05986 / ewc: 0.0 / total: 0.05986: : 469it [00:01, 372.26it/s]\n",
      "=> task: 6/10 | epoch: 27/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.05382 / ewc: 0.0 / total: 0.05382: : 469it [00:01, 363.96it/s]\n",
      "=> task: 6/10 | epoch: 28/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.04878 / ewc: 0.0 / total: 0.04878: : 469it [00:01, 382.60it/s] \n",
      "=> task: 6/10 | epoch: 29/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.04312 / ewc: 0.0 / total: 0.04312: : 469it [00:01, 385.32it/s]\n",
      "=> task: 6/10 | epoch: 30/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.03826 / ewc: 0.0 / total: 0.03826: : 469it [00:01, 372.93it/s]\n",
      "=> task: 6/10 | epoch: 31/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.03288 / ewc: 0.0 / total: 0.03288: : 469it [00:01, 373.06it/s]\n",
      "=> task: 6/10 | epoch: 32/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.02864 / ewc: 0.0 / total: 0.02864: : 469it [00:01, 373.51it/s]\n",
      "=> task: 6/10 | epoch: 33/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.0248 / ewc: 0.0 / total: 0.0248: : 469it [00:01, 378.69it/s]  \n",
      "=> task: 6/10 | epoch: 34/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.02098 / ewc: 0.0 / total: 0.02098: : 469it [00:01, 375.72it/s]\n",
      "=> task: 6/10 | epoch: 35/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01796 / ewc: 0.0 / total: 0.01796: : 469it [00:01, 369.68it/s]\n",
      "=> task: 6/10 | epoch: 36/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01544 / ewc: 0.0 / total: 0.01544: : 469it [00:01, 373.98it/s]\n",
      "=> task: 6/10 | epoch: 37/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01357 / ewc: 0.0 / total: 0.01357: : 469it [00:01, 370.53it/s]\n",
      "=> task: 6/10 | epoch: 38/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01198 / ewc: 0.0 / total: 0.01198: : 469it [00:01, 364.18it/s]\n",
      "=> task: 6/10 | epoch: 39/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01074 / ewc: 0.0 / total: 0.01074: : 469it [00:01, 360.65it/s]\n",
      "=> task: 6/10 | epoch: 40/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.009659 / ewc: 0.0 / total: 0.009659: : 469it [00:01, 379.21it/s] \n",
      "=> task: 6/10 | epoch: 41/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.009063 / ewc: 0.0 / total: 0.009063: : 469it [00:01, 376.66it/s] \n",
      "=> task: 6/10 | epoch: 42/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.008177 / ewc: 0.0 / total: 0.008177: : 469it [00:01, 365.57it/s]  \n",
      "=> task: 6/10 | epoch: 43/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.00757 / ewc: 0.0 / total: 0.00757: : 469it [00:01, 381.41it/s]    \n",
      "=> task: 6/10 | epoch: 44/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.007299 / ewc: 0.0 / total: 0.007299: : 469it [00:01, 370.40it/s]  \n",
      "=> task: 6/10 | epoch: 45/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.006688 / ewc: 0.0 / total: 0.006688: : 469it [00:01, 362.49it/s]  \n",
      "=> task: 6/10 | epoch: 46/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.006344 / ewc: 0.0 / total: 0.006344: : 469it [00:01, 364.18it/s]  \n",
      "=> task: 6/10 | epoch: 47/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.006092 / ewc: 0.0 / total: 0.006092: : 469it [00:01, 377.71it/s]  \n",
      "=> task: 6/10 | epoch: 48/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.005809 / ewc: 0.0 / total: 0.005809: : 469it [00:01, 373.28it/s]  \n",
      "=> task: 6/10 | epoch: 49/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.005595 / ewc: 0.0 / total: 0.005595: : 469it [00:01, 363.49it/s]  \n",
      "=> task: 6/10 | epoch: 50/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.005458 / ewc: 0.0 / total: 0.005458: : 469it [00:01, 354.91it/s]  \n",
      "=> task: 6/10 | epoch: 51/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.005133 / ewc: 0.0 / total: 0.005133: : 469it [00:01, 380.09it/s]  \n",
      "=> task: 6/10 | epoch: 52/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.005031 / ewc: 0.0 / total: 0.005031: : 469it [00:01, 358.77it/s] \n",
      "=> task: 6/10 | epoch: 53/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.004843 / ewc: 0.0 / total: 0.004843: : 469it [00:01, 356.03it/s]  \n",
      "=> task: 6/10 | epoch: 54/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.00473 / ewc: 0.0 / total: 0.00473: : 469it [00:01, 369.50it/s]   \n",
      "=> task: 6/10 | epoch: 55/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.004485 / ewc: 0.0 / total: 0.004485: : 469it [00:01, 381.04it/s]  \n",
      "=> task: 6/10 | epoch: 56/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.004435 / ewc: 0.0 / total: 0.004435: : 469it [00:01, 378.46it/s]  \n",
      "=> task: 6/10 | epoch: 57/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.004228 / ewc: 0.0 / total: 0.004228: : 469it [00:01, 358.09it/s]  \n",
      "=> task: 6/10 | epoch: 58/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.004177 / ewc: 0.0 / total: 0.004177: : 469it [00:01, 375.22it/s]  \n",
      "=> task: 6/10 | epoch: 59/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.004039 / ewc: 0.0 / total: 0.004039: : 469it [00:01, 381.75it/s]  \n",
      "=> task: 6/10 | epoch: 60/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.003896 / ewc: 0.0 / total: 0.003896: : 469it [00:01, 380.65it/s]  \n",
      "=> task: 7/10 | epoch: 1/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.2126 / ewc: 0.0 / total: 0.2126: : 469it [00:01, 372.37it/s]  \n",
      "=> task: 7/10 | epoch: 2/60 | progress: [60032/60000] (100%) | prec: 0.9792 | loss => ce: 0.1939 / ewc: 0.0 / total: 0.1939: : 469it [00:01, 367.08it/s] \n",
      "=> task: 7/10 | epoch: 3/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1872 / ewc: 0.0 / total: 0.1872: : 469it [00:01, 382.10it/s] \n",
      "=> task: 7/10 | epoch: 4/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1788 / ewc: 0.0 / total: 0.1788: : 469it [00:01, 373.80it/s]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> task: 7/10 | epoch: 5/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1751 / ewc: 0.0 / total: 0.1751: : 469it [00:01, 368.25it/s] \n",
      "=> task: 7/10 | epoch: 6/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1701 / ewc: 0.0 / total: 0.1701: : 469it [00:01, 373.36it/s] \n",
      "=> task: 7/10 | epoch: 7/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1629 / ewc: 0.0 / total: 0.1629: : 469it [00:01, 375.50it/s] \n",
      "=> task: 7/10 | epoch: 8/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1568 / ewc: 0.0 / total: 0.1568: : 469it [00:01, 365.69it/s] \n",
      "=> task: 7/10 | epoch: 9/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1513 / ewc: 0.0 / total: 0.1513: : 469it [00:01, 373.58it/s] \n",
      "=> task: 7/10 | epoch: 10/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1451 / ewc: 0.0 / total: 0.1451: : 469it [00:01, 380.56it/s] \n",
      "=> task: 7/10 | epoch: 11/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1395 / ewc: 0.0 / total: 0.1395: : 469it [00:01, 378.78it/s]  \n",
      "=> task: 7/10 | epoch: 12/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.133 / ewc: 0.0 / total: 0.133: : 469it [00:01, 379.44it/s]    \n",
      "=> task: 7/10 | epoch: 13/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1269 / ewc: 0.0 / total: 0.1269: : 469it [00:01, 388.31it/s]  \n",
      "=> task: 7/10 | epoch: 14/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1194 / ewc: 0.0 / total: 0.1194: : 469it [00:01, 374.46it/s]  \n",
      "=> task: 7/10 | epoch: 15/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1129 / ewc: 0.0 / total: 0.1129: : 469it [00:01, 379.54it/s]  \n",
      "=> task: 7/10 | epoch: 16/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.1062 / ewc: 0.0 / total: 0.1062: : 469it [00:01, 361.48it/s] \n",
      "=> task: 7/10 | epoch: 17/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.09821 / ewc: 0.0 / total: 0.09821: : 469it [00:01, 372.94it/s]\n",
      "=> task: 7/10 | epoch: 18/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.09243 / ewc: 0.0 / total: 0.09243: : 469it [00:01, 368.67it/s]\n",
      "=> task: 7/10 | epoch: 19/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.08424 / ewc: 0.0 / total: 0.08424: : 469it [00:01, 380.74it/s]\n",
      "=> task: 7/10 | epoch: 20/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.0768 / ewc: 0.0 / total: 0.0768: : 469it [00:01, 385.12it/s]   \n",
      "=> task: 7/10 | epoch: 21/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.07008 / ewc: 0.0 / total: 0.07008: : 469it [00:01, 376.30it/s]\n",
      "=> task: 7/10 | epoch: 22/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.06293 / ewc: 0.0 / total: 0.06293: : 469it [00:01, 372.14it/s]\n",
      "=> task: 7/10 | epoch: 23/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.05706 / ewc: 0.0 / total: 0.05706: : 469it [00:01, 382.20it/s]\n",
      "=> task: 7/10 | epoch: 24/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.05017 / ewc: 0.0 / total: 0.05017: : 469it [00:01, 379.09it/s] \n",
      "=> task: 7/10 | epoch: 25/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.04431 / ewc: 0.0 / total: 0.04431: : 469it [00:01, 384.69it/s] \n",
      "=> task: 7/10 | epoch: 26/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.03851 / ewc: 0.0 / total: 0.03851: : 469it [00:01, 379.53it/s] \n",
      "=> task: 7/10 | epoch: 27/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.03308 / ewc: 0.0 / total: 0.03308: : 469it [00:01, 377.88it/s]\n",
      "=> task: 7/10 | epoch: 28/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.02769 / ewc: 0.0 / total: 0.02769: : 469it [00:01, 374.08it/s]\n",
      "=> task: 7/10 | epoch: 29/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.02361 / ewc: 0.0 / total: 0.02361: : 469it [00:01, 380.71it/s]\n",
      "=> task: 7/10 | epoch: 30/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01968 / ewc: 0.0 / total: 0.01968: : 469it [00:01, 381.73it/s] \n",
      "=> task: 7/10 | epoch: 31/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01663 / ewc: 0.0 / total: 0.01663: : 469it [00:01, 374.45it/s] \n",
      "=> task: 7/10 | epoch: 32/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01426 / ewc: 0.0 / total: 0.01426: : 469it [00:01, 370.26it/s] \n",
      "=> task: 7/10 | epoch: 33/60 | progress: [60032/60000] (100%) | prec: 0.9896 | loss => ce: 0.01216 / ewc: 0.0 / total: 0.01216: : 469it [00:01, 381.89it/s]\n",
      "=> task: 7/10 | epoch: 34/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.01107 / ewc: 0.0 / total: 0.01107: : 469it [00:01, 384.32it/s]   \n",
      "=> task: 7/10 | epoch: 35/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.009767 / ewc: 0.0 / total: 0.009767: : 469it [00:01, 368.61it/s] \n",
      "=> task: 7/10 | epoch: 36/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.008863 / ewc: 0.0 / total: 0.008863: : 469it [00:01, 378.69it/s]  \n",
      "=> task: 7/10 | epoch: 37/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.008247 / ewc: 0.0 / total: 0.008247: : 469it [00:01, 381.92it/s]  \n",
      "=> task: 7/10 | epoch: 38/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.007405 / ewc: 0.0 / total: 0.007405: : 469it [00:01, 373.77it/s]  \n",
      "=> task: 7/10 | epoch: 39/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.007088 / ewc: 0.0 / total: 0.007088: : 469it [00:01, 393.70it/s]  \n",
      "=> task: 7/10 | epoch: 40/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.006659 / ewc: 0.0 / total: 0.006659: : 469it [00:01, 381.08it/s]  \n",
      "=> task: 7/10 | epoch: 41/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.006269 / ewc: 0.0 / total: 0.006269: : 469it [00:01, 369.34it/s] \n",
      "=> task: 7/10 | epoch: 42/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.006001 / ewc: 0.0 / total: 0.006001: : 469it [00:01, 366.73it/s]  \n",
      "=> task: 7/10 | epoch: 43/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.005693 / ewc: 0.0 / total: 0.005693: : 469it [00:01, 370.06it/s]  \n",
      "=> task: 7/10 | epoch: 44/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.00547 / ewc: 0.0 / total: 0.00547: : 469it [00:01, 378.30it/s]    \n",
      "=> task: 7/10 | epoch: 45/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.005147 / ewc: 0.0 / total: 0.005147: : 469it [00:01, 375.12it/s]  \n",
      "=> task: 7/10 | epoch: 46/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.004994 / ewc: 0.0 / total: 0.004994: : 469it [00:01, 381.59it/s]  \n",
      "=> task: 7/10 | epoch: 47/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.004816 / ewc: 0.0 / total: 0.004816: : 469it [00:01, 371.60it/s]  \n",
      "=> task: 7/10 | epoch: 48/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.004547 / ewc: 0.0 / total: 0.004547: : 469it [00:01, 374.22it/s]  \n",
      "=> task: 7/10 | epoch: 49/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.004465 / ewc: 0.0 / total: 0.004465: : 469it [00:01, 380.66it/s]  \n",
      "=> task: 7/10 | epoch: 50/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.004321 / ewc: 0.0 / total: 0.004321: : 469it [00:01, 380.32it/s]  \n",
      "=> task: 7/10 | epoch: 51/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.004207 / ewc: 0.0 / total: 0.004207: : 469it [00:01, 364.83it/s]  \n",
      "=> task: 7/10 | epoch: 52/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.004026 / ewc: 0.0 / total: 0.004026: : 469it [00:01, 370.62it/s]  \n",
      "=> task: 7/10 | epoch: 53/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.003912 / ewc: 0.0 / total: 0.003912: : 469it [00:01, 379.44it/s]  \n",
      "=> task: 7/10 | epoch: 54/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.003768 / ewc: 0.0 / total: 0.003768: : 469it [00:01, 382.22it/s]  \n",
      "=> task: 7/10 | epoch: 55/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.003737 / ewc: 0.0 / total: 0.003737: : 469it [00:01, 378.37it/s]  \n",
      "=> task: 7/10 | epoch: 56/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.003573 / ewc: 0.0 / total: 0.003573: : 469it [00:01, 372.65it/s]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> task: 7/10 | epoch: 57/60 | progress: [60032/60000] (100%) | prec: 1.0 | loss => ce: 0.003509 / ewc: 0.0 / total: 0.003509: : 469it [00:01, 378.37it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-eb8656238e75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m  \u001b[0mstandard_total_loss_no_dropout_no_earlystopping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m  \u001b[0mstandard_ce_loss_no_dropout_no_earlystopping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m  \u001b[0mstandard_ewc_loss_no_dropout_no_earlystopping\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmlp_no_dropout_no_earlystopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mepochs_per_task\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/University-Coding/Masters_thesis/final/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, epochs_per_task, batch_size, consolidate, fisher_estimation_sample_size, lr, weight_decay, do_early_stopping, cuda)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0macc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_precision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/University-Coding/Masters_thesis/final/utils.py\u001b[0m in \u001b[0;36mvalidate_precision\u001b[0;34m(model, data_loader, cuda, verbose)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# update statistics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MastersThesis/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/University-Coding/Masters_thesis/final/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MastersThesis/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MastersThesis/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MastersThesis/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run the standard experiment.\n",
    "(standard_prec_no_dropout_no_earlystopping, \n",
    " standard_total_loss_no_dropout_no_earlystopping,\n",
    " standard_ce_loss_no_dropout_no_earlystopping,\n",
    " standard_ewc_loss_no_dropout_no_earlystopping) = train(\n",
    "    mlp_no_dropout_no_earlystopping, train_loader, test_loader,\n",
    "    epochs_per_task,\n",
    "    batch_size,\n",
    "    consolidate,\n",
    "    fisher_estimation_sample_size,\n",
    "    lr,\n",
    "    weight_decay,\n",
    "    early_stopping,\n",
    "    cuda\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot(standard_total_loss_no_dropout_no_earlystopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_plot(standard_prec_no_dropout_no_earlystopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_consolidation_no_dropout_no_earlystopping = MLP( 28*28, 10,\n",
    "    hidden_size1,\n",
    "    hidden_size2,\n",
    "    hidden_dropout_prob,\n",
    "    input_dropout_prob,\n",
    "    lamda,\n",
    ")\n",
    "\n",
    "utils.gaussian_initialize(mlp_consolidation_no_dropout_no_earlystopping)\n",
    "\n",
    "# run the standard experiment.\n",
    "consolidate = True\n",
    "(ewc_prec_no_dropout_no_earlystopping, \n",
    " ewc_total_loss_no_dropout_no_earlystopping, \n",
    " ewc_ce_loss_no_dropout_no_earlystopping, \n",
    " ewc_ewc_loss_no_dropout_no_earlystopping) = train(\n",
    "    mlp_consolidation_no_dropout_no_earlystopping, train_loader, test_loader,\n",
    "    epochs_per_task,\n",
    "    batch_size,\n",
    "    consolidate,\n",
    "    fisher_estimation_sample_size,\n",
    "    lr,\n",
    "    weight_decay,\n",
    "    early_stopping,\n",
    "    cuda\n",
    ")\n",
    "\n",
    "if cuda:\n",
    "    mlp_consolidation_no_dropout_no_earlystopping.cuda()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot(ewc_total_loss_no_dropout_no_earlystopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_plot(ewc_prec_no_dropout_no_earlystopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#high learning rate, dropout, no early stopping\n",
    "hidden_dropout_prob = 0.5\n",
    "input_dropout_prob = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the model.\n",
    "mlp_dropout_no_earlystopping = MLP(28*28, 10,\n",
    "    hidden_size1,\n",
    "    hidden_size2,\n",
    "    hidden_dropout_prob,\n",
    "    input_dropout_prob,\n",
    "    lamda,\n",
    ")\n",
    "\n",
    "# initialize the weights.\n",
    "utils.gaussian_initialize(mlp_dropout_no_earlystopping)\n",
    "\n",
    "# run the standard experiment.\n",
    "consolidate = False\n",
    "(standard_prec_dropout_no_earlystopping,\n",
    " standard_total_loss_dropout_no_earlystopping,\n",
    " standard_ce_loss_dropout_no_earlystopping,\n",
    " standard_ewc_loss_dropout_no_earlystopping) = train(\n",
    "    mlp_dropout_no_earlystopping, train_loader, test_loader,\n",
    "    epochs_per_task,\n",
    "    batch_size,\n",
    "    consolidate,\n",
    "    fisher_estimation_sample_size,\n",
    "    lr,\n",
    "    weight_decay,\n",
    "    early_stopping,\n",
    "    cuda\n",
    ")\n",
    "\n",
    "if cuda:\n",
    "    mlp_dropout_no_earlystopping.cuda()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot(standard_total_loss_dropout_no_earlystopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_plot(standard_prec_dropout_no_earlystopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_consolidation_dropout_no_earlystopping = MLP(28*28, 10,\n",
    "    hidden_size1,\n",
    "    hidden_size2,\n",
    "    hidden_dropout_prob,\n",
    "    input_dropout_prob,\n",
    "    lamda,\n",
    ")\n",
    "\n",
    "utils.gaussian_initialize(mlp_consolidation_dropout_no_earlystopping)\n",
    "\n",
    "# run the standard experiment.\n",
    "consolidate = True\n",
    "(ewc_prec_dropout_no_earlystopping, \n",
    " ewc_total_loss_dropout_no_earlystopping, \n",
    " ewc_ce_loss_dropout_no_earlystopping, \n",
    " ewc_ewc_loss_dropout_no_earlystopping) =train(\n",
    "    mlp_consolidation_dropout_no_earlystopping, train_loader, test_loader,\n",
    "    epochs_per_task,\n",
    "    batch_size,\n",
    "    consolidate,\n",
    "    fisher_estimation_sample_size,\n",
    "    lr,\n",
    "    weight_decay,\n",
    "    early_stopping,\n",
    "    cuda\n",
    ")\n",
    "\n",
    "if cuda:\n",
    "    mlp_consolidation_dropout_no_earlystopping.cuda()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot(ewc_total_loss_dropout_no_earlystopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_plot(ewc_prec_dropout_no_earlystopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropout and early stopping\n",
    "early_stopping = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_dropout_earlystopping = MLP(28*28, 10,\n",
    "    hidden_size1,\n",
    "    hidden_size2,\n",
    "    hidden_dropout_prob,\n",
    "    input_dropout_prob,\n",
    "    lamda,\n",
    ")\n",
    "\n",
    "utils.gaussian_initialize(mlp_dropout_earlystopping)\n",
    "\n",
    "# run the standard experiment.\n",
    "consolidate = False\n",
    "(standard_prec_dropout_earlystopping, \n",
    " standard_total_loss_dropout_earlystopping,\n",
    " standard_ce_loss_dropout_earlystopping,\n",
    " standard_ewc_loss_dropout_earlystopping) = train(\n",
    "    mlp_dropout_earlystopping, train_loader, test_loader,\n",
    "    epochs_per_task,\n",
    "    batch_size,\n",
    "    consolidate,\n",
    "    fisher_estimation_sample_size,\n",
    "    lr,\n",
    "    weight_decay,\n",
    "    early_stopping,\n",
    "    cuda\n",
    ")\n",
    "\n",
    "if cuda:\n",
    "    mlp_dropout_earlystopping.cuda()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot(standard_total_loss_dropout_earlystopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_plot(standard_prec_dropout_earlystopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_consolidation_dropout_earlystopping = MLP(28*28, 10,\n",
    "    hidden_size1,\n",
    "    hidden_size2,\n",
    "    hidden_dropout_prob,\n",
    "    input_dropout_prob,\n",
    "    lamda,\n",
    ")\n",
    "\n",
    "utils.gaussian_initialize(mlp_consolidation_dropout_earlystopping)\n",
    "\n",
    "# run the standard experiment.\n",
    "consolidate = True\n",
    "(ewc_prec_dropout_earlystopping,\n",
    " ewc_total_loss_dropout_earlystopping, \n",
    " ewc_ce_loss_dropout_earlystopping,\n",
    " ewc_ewc_loss_dropout_earlystopping) =train(\n",
    "    mlp_consolidation_dropout_earlystopping, train_loader, test_loader,\n",
    "    epochs_per_task,\n",
    "    batch_size,\n",
    "    consolidate,\n",
    "    fisher_estimation_sample_size,\n",
    "    lr,\n",
    "    weight_decay,\n",
    "    early_stopping,\n",
    "    cuda\n",
    ")\n",
    "\n",
    "if cuda:\n",
    "    mlp_consolidation_dropout_earlystopping.cuda()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot(ewc_total_loss_dropout_earlystopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_plot(ewc_prec_dropout_earlystopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropout, early stopping, wider layers, higher lambda\n",
    "hidden_size1 = 1500\n",
    "hidden_size2 = 1000\n",
    "lamda = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#does even higher lambda + greater network size help to get better long term results + more epochs\n",
    "mlp_optimised = MLP(28*28, 10,\n",
    "    hidden_size1,\n",
    "    hidden_size2,\n",
    "    hidden_dropout_prob,\n",
    "    input_dropout_prob,\n",
    "    lamda,\n",
    ")\n",
    "\n",
    "utils.gaussian_initialize(mlp_optimised)\n",
    "\n",
    "# run the standard experiment.\n",
    "consolidate = False\n",
    "(standard_prec_optimised,\n",
    " standard_total_loss_optimised,\n",
    " standard_ce_loss_optimised, \n",
    " standard_ewc_loss_optimised) =train(\n",
    "    mlp_optimised, train_loader, test_loader,\n",
    "    epochs_per_task,\n",
    "    batch_size,\n",
    "    consolidate,\n",
    "    fisher_estimation_sample_size,\n",
    "    lr,\n",
    "    weight_decay,\n",
    "    early_stopping,\n",
    "    cuda\n",
    ")\n",
    "\n",
    "if cuda:\n",
    "    mlp_optimised.cuda()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot(standard_total_loss_optimised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_plot(standard_prec_optimised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#does even higher lambda + greater network size help to get better long term results + more epochs\n",
    "mlp_consolidation_optimised = MLP(28*28, 10,\n",
    "    hidden_size1,\n",
    "    hidden_size2,\n",
    "    hidden_dropout_prob,\n",
    "    input_dropout_prob,\n",
    "    lamda,\n",
    ")\n",
    "\n",
    "utils.gaussian_initialize(mlp_consolidation_optimised)\n",
    "\n",
    "# run the standard experiment.\n",
    "consolidate = True\n",
    "(ewc_prec_optimised, \n",
    " ewc_total_loss_optimised,\n",
    " ewc_ce_loss_optimised, \n",
    " ewc_ewc_loss_optimised) =train(\n",
    "    mlp_consolidation_optimised, train_loader, test_loader,\n",
    "    epochs_per_task,\n",
    "    batch_size,\n",
    "    consolidate,\n",
    "    fisher_estimation_sample_size,\n",
    "    lr,\n",
    "    weight_decay,\n",
    "    early_stopping,\n",
    "    cuda\n",
    ")\n",
    "\n",
    "if cuda:\n",
    "    mlp_consolidation_optimised.cuda()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot(ewc_total_loss_optimised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_plot(ewc_prec_optimised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare performance on first task:\n",
    "fig = plt.figure(figsize = (20,10))\n",
    "plt.ylim(0.65,1)\n",
    "plt.plot(range(1, len(standard_prec_no_dropout_no_earlystopping)+1),\n",
    "         standard_prec_no_dropout_no_earlystopping, label = 'std_no_drop_no_stop')\n",
    "plt.plot(range(1, len(ewc_prec_no_dropout_no_earlystopping)+1),\n",
    "         ewc_prec_no_dropout_no_earlystopping, label = 'ewc_no_drop_no_stop')\n",
    "plt.plot(range(1, len(standard_prec_dropout_no_earlystopping)+1),\n",
    "         standard_prec_dropout_no_earlystopping, label = 'std_drop_no_stop')\n",
    "plt.plot(range(1, len(ewc_prec_dropout_no_earlystopping)+1),\n",
    "         ewc_prec_dropout_no_earlystopping, label = 'ewc_drop_no_stop')\n",
    "plt.plot(range(1, len(standard_prec_dropopout_earlystopping)+1),\n",
    "         standard_prec_dropout_earlystopping, label = 'std_drop_stop')\n",
    "plt.plot(range(1, len(ewc_prec_dropout_earlystopping)+1),\n",
    "         ewc_prec_dropout_earlystopping, label = 'ewc_drop_stop')\n",
    "plt.plot(range(1, len(standard_prec_optimised)+1),\n",
    "         standard_prec_optimised, label = 'std_opt')\n",
    "plt.plot(range(1, len(ewc_prec_optimised)+1),\n",
    "         ewc_prec_optimised, label = 'ewc_opt')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamda = 800\n",
    "lr = 1.e-2\n",
    "#does even higher lambda + greater network size help to get better long term results + more epochs\n",
    "mlp_consolidation_optimised2 = MLP(28*28, 10,\n",
    "    hidden_size1,\n",
    "    hidden_size2,\n",
    "    hidden_dropout_prob,\n",
    "    input_dropout_prob,\n",
    "    lamda,\n",
    ")\n",
    "\n",
    "utils.gaussian_initialize(mlp_consolidation_optimised2)\n",
    "\n",
    "# run the standard experiment.\n",
    "consolidate = True\n",
    "(ewc_prec_optimised2, \n",
    " ewc_total_loss_optimised2,\n",
    " ewc_ce_loss_optimised2, \n",
    " ewc_ewc_loss_optimised2) =train(\n",
    "    mlp_consolidation_optimised2, train_loader, test_loader,\n",
    "    epochs_per_task,\n",
    "    batch_size,\n",
    "    consolidate,\n",
    "    fisher_estimation_sample_size,\n",
    "    lr,\n",
    "    weight_decay,\n",
    "    early_stopping,\n",
    "    cuda\n",
    ")\n",
    "\n",
    "if cuda:\n",
    "    mlp_consolidation_optimised2.cuda()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot(ewc_total_loss_optimised2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_plot(ewc_prec_optimised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
